,question,contexts,ground_truth,evolution_type,metadata,episode_done
0,Wie bringt die interne Datenakademie der Merck KGaA den Fachbereichen Themen wie generative KI näher?,"['Wieviel KI müssen wir unseren Kunden erklären?\n\nWährend Menschen immer weiter von KI unterstützt werden und das Leben scheinbar einfacher wird, nimmt die technische Komplexität unserer Welt ständig zu. Wo vor zehn Jahren noch ein grundsätzliches Verständnis von Web- Technologien ausreichte, um ""das moderne Leben"" zu begreifen, nimmt die Halbwertszeit selbst von Expertenwissen in der KI immer weiter ab.\n\nFür uns gibt es Konferenzen. Doch wieviel KI muss der Fachbereich begreifen, um nicht komplett abgehängt zu werden? Von wie wenig Vorwissen müssen wir ausgehen, wenn wir Data Analytics und KI-Lösungen mit nichttechnischen Personen diskutieren? Egal ob interne Datenabteilung oder externer Dienstleister: Welche Erklärungen müssen folgen, wenn der Fachbereich denkt, dass wir etwas ""einfach mit KI lösen…""?\n\nVorkenntnisse\n\nKeine Vorkenntnisse erforderlich. Lediglich ein Interesse an der Thematik, die über den technischen Aspekt hinausgeht.\n\nLernziele\n\nIch plane Impulse für all diejenigen zu geben, die mit nichttechnischen Personen über KI sprechen wollen und müssen: beim Tischgespräch in der Familie, beim Kundenpitch oder als Verantwortliche für Datenkultur, Change Management oder in der Politik.\n\nAnhand der Merck KGaA zeige ich, wie wir diese Themen den Fachbereichen näherbringen, etwa durch eine interne Datenakademie, in der Interessierte bis hin zum ""Citizen Data Scientist"" ausgebildet werden können.\n\nSpeaker\n\nBoris Adryan ist der Akademische Direktor der internen Data & Digital Academy beim chemisch-pharmazeutischen Unternehmen Merck KGaA. Dort plant und liefert er die Lerninhalte für alle Themen vom grundsätzlichen Datenverständnis bis hin zu generativer KI. Eigene Erfahrung sammelte er in einem Jahrzehnt akademischer Forschung im Bereich angewandter ML sowie als Data Scientist in der Industrie. Jetzt Tickets sichern']","Die interne Datenakademie der Merck KGaA bringt den Fachbereichen Themen wie generative KI näher, indem sie Interessierte bis hin zum 'Citizen Data Scientist' ausbildet.",simple,"[{'source': '../data/Wieviel_KI_müssen_wir_unseren_Kunden_erklären_.md', 'filename': '../data/Wieviel_KI_müssen_wir_unseren_Kunden_erklären_.md'}]",True
1,Wie hat die Einführung der Transformer-Architektur durch Google die Entwicklung neuer Modelle beeinflusst?,"['Eine Einführung in Large Language Models\n\nChatGPT ist fast schon zum Synonym für große Sprachmodelle geworden. Doch das ist nur die Spitze des Eisbergs – es gibt diese Modelle in viel mehr unterschiedlichen Ausprägungen.\n\nNach der Einführung der Transformer-Architektur durch Google gab es eine wahre Explosion an neuen Modellen. Grundsätzlich kann man zwischen Encoder- und (generativen) Decoder-Modellen unterscheiden, die sich für unterschiedliche Aufgaben eignen.\n\nDieser Vortrag gibt einen Überblick über die Architektur und die Entwicklung der unterschiedlichen Modelle. Er zeigt, dass sich Modelle auch leicht auf eigener Hardware oder mit kostenlosen Cloud-Diensten ausprobieren lassen und wie man das mit etwas Mühe auch ohne GPU auf der eigenen Hardware ausprobieren kann.\n\nDer Ausblick wagt eine Vorhersage, wie es mit den großen Sprachmodellen vielleicht weitergehen könnte.\n\nVorkenntnisse\n\nMit Sprachmodellen als Anwender hat vermutlich jeder/r schon gearbeitet. Grundkenntnisse in Machine Learning sind ebenso hilfreich wie ein Grundverständnis von CPUs, GPUs und Arbeitsspeicher.\n\nLernziele\n\nVerständnis der Architektur von großen Sprachmodellen\n\nUnterscheidung von Encoder- und Decoder-Modellen\n\nOptimierungsmöglichkeiten für Sprachmodelle\n\nKenntnis unterschiedlicher generativer Modelle\n\n""Gefühl"" für die weitere Entwicklung\n\nSpeaker\n\nChristian Winkler beschäftigt sich seit vielen Jahre mit künstlicher Intelligenz, speziell in der automatisierten Analyse natürlichsprachiger Texte (NLP). Als Professor an der TH Nürnberg konzentriert er sich auf die Optimierung von User Experience mithilfe moderner Verfahren. Er forscht und publiziert zu Natural Language Processing und ist regelmäßig Sprecher auf Machine Learning-Konferenzen. Jetzt Tickets sichern']",Nach der Einführung der Transformer-Architektur durch Google gab es eine wahre Explosion an neuen Modellen.,simple,"[{'source': '../data/Eine_Einführung_in_Large_Language_Models.md', 'filename': '../data/Eine_Einführung_in_Large_Language_Models.md'}]",True
2,"Wie können Data Scientists realistisches Erwartungsmanagement betreiben, um maximalen Business Impact zu erzielen?","['KI Power-Play: Realistisches Erwartungsmanagement für maximalen Business\n\nImpact Mit dem Hype um GenAI stehen wir als Data Scientists vor der Herausforderung, die hohen (und manchmal unrealistischen) Erwartungen an KI zu managen.\n\nEs braucht die richtigen Herangehensweisen, um mit Daten und KI echten Business Impact zu schaffen, und um somit Enttäuschungen zu vermeiden. Dabei ist es wichtig effiziente Kollaboration zwischen Data Scientists und Business Experten zu ermöglichen. Letztendlich können wir dann sogar GenAI nutzen, um uns bei dieser Herausforderung zu unterstützen.\n\nSpeaker\n\nKira Engelhardt studierte Data Science an der LMU in München und verfügt über mehr als ein Jahrzehnt relevante Erfahrung in der Transformation wichtiger Geschäftsprozesse durch Data Science, Daten und KI. Sie begann ihre Karriere in der Finanzbranche und arbeitete als Data Scientist bei HUK Coburg, KPMG und der Allianz. Nach mehreren Jahren Erfahrung als KI-Projektleiterin in Deutschland und Schweden bei E.ON leitet sie nun das globale Data- und KI- Inhouse-Consulting-Team für Energy Networks bei E.ON. Ihr Ziel ist es, die Digitalisierung unserer Strom- und Gasnetze voranzutreiben und so die Energiewende zu ermöglichen. Jetzt Tickets sichern']","Data Scientists können realistisches Erwartungsmanagement betreiben, indem sie die richtigen Herangehensweisen nutzen, um mit Daten und KI echten Business Impact zu schaffen. Es ist wichtig, eine effiziente Kollaboration zwischen Data Scientists und Business Experten zu ermöglichen. Letztendlich kann sogar GenAI genutzt werden, um bei dieser Herausforderung zu unterstützen.",simple,"[{'source': '../data/KI_Power-Play__Realistisches_Erwartungsmanagement_für_maximalen_Business_Impact.md', 'filename': '../data/KI_Power-Play__Realistisches_Erwartungsmanagement_für_maximalen_Business_Impact.md'}]",True
3,Wie tragen Data-Governance und MLOps-Techniken zur technischen Bereitschaft für die Einhaltung des EU AI Act bei?,"['Die Engineering-Perspektive auf den EU AI Act\n\nTrustworthy AI ist eine zentrale Motivation hinter dem EU AI Act. Dieser gesetzliche Rahmen legt vielschichtige und anspruchsvolle Anforderungen an KI- Systeme fest und kategorisiert sie in vier Risikogruppen: verbotene, hochriskante, begrenzt riskante KI-Systeme und solche mit minimalem Risiko.\n\nAngesichts der Schonfrist von 6 bis 24 Monaten nach Veröffentlichung der Verordnung wird empfohlen, dass Unternehmen, die KI einsetzen, mit der Vorbereitung auf die zukünftigen Anforderungen beginnen. Um die technische Bereitschaft für die Einhaltung des AI Act zu erreichen, ist es wesentlich, etablierte Data-Governance, KI-Governance und MLOps-Techniken über die gesamte Lebensdauer eines ML/AI-Systems anzuwenden.\n\nDieser Vortrag zielt darauf ab, Entwickler und Data Science Teams mit einem umfassenden Verständnis der Anforderungen des EU AI Act auszustatten. Er bietet auch praktische Anleitungen zur Implementierung von MLOps und Data- Governance-Prozessen, die der Verordnung entsprechen. Dieser Vortrag wird die Ingenieursperspektive auf die proaktive Implementierung des EU AI Act geben.\n\nVorkenntnisse\n\nErfahrung mit MLOps\n\nLernziele\n\nNach dem Talk sind ML Engineers in der Lage, proaktiv konforme MLOps-Prozesse und -Systeme zu entwerfen und zu implementieren und dabei die regulatorischen Anforderungen effektiv zu meistern.\n\nSpeaker\n\nLarysa Visengeriyeva ist Technologieberaterin und Expertin für Datenqualität, maschinelles Lernen und MLOps. Sie promovierte in Augmented Data Quality Management an der TU Berlin. Bei INNOQ.AI ist sie Head of Data and AI und arbeitet an der Operationalisierung von ML-Systemen und Datenarchitekturen. Larysa gründete das Sommerfestival Women+ in Data and AI. __@visenger Jetzt Tickets sichern']","Data-Governance und MLOps-Techniken tragen zur technischen Bereitschaft für die Einhaltung des EU AI Act bei, indem sie über die gesamte Lebensdauer eines ML/AI-Systems angewendet werden. Diese Techniken helfen, die Anforderungen des AI Act zu erfüllen und sicherzustellen, dass KI-Systeme den festgelegten Richtlinien entsprechen.",simple,"[{'source': '../data/Die_Engineering-Perspektive_auf_den_EU_AI_Act.md', 'filename': '../data/Die_Engineering-Perspektive_auf_den_EU_AI_Act.md'}]",True
4,Wie wird die Sentimentanalyse mit LLMs im Workshop durchgeführt?,"['Datenanalyse mit Machine Learning\n\nIn diesem Workshop führen wir ein Analyseprojekt durch und nutzen dazu unterschiedliche Methoden.\n\nBasis bilden unstrukturierte Daten aus dem Technology-Subreddit, die wir zunächst statistisch analysieren. Anschließend werden wir die Datenmenge mittels Klassifikation einengen und versuchen, die Inhalte genauer zu verstehen. Dazu kommt Topic Modeling als unüberwachtes Machine Learning im Bereich NLP zum Einsatz.\n\nSchließlich werden wir die Sentiments mit LLMs bestimmen. Daraus ergeben sich Zeitserien, die wir analysieren die zukünftige Entwicklung mit unterschiedlichen Methoden vorhersagen.\n\nVorkenntnisse\n\nPython wäre hilfreich, muss aber nicht unbedingt sein Wer seinen eigenen Computer nutzen will, sollte Jupyter installieren, es geht aber auch mit Colab.\n\nLernziele\n\nKennenlernen unterschiedlicher Datenanalysemethoden\n\nÜberwachtes und unüberwachtes Machine Learning\n\nLLMs und Transformer\n\nZeitserien-Vorhersagen\n\nProjektablauf in komplexen Analyseprojekten kennenlernen\n\nAgenda\n\nPausenzeiten * ab 09:00 Uhr: Registrierung und Begrüßungskaffee * 10:00 Uhr: Beginn * 12:30 - 13:30 Uhr: Mittagspause * 15:00 - 15:15 Uhr: Kaffeepause * 16:15 - 16:30 Uhr: Kaffeepause * ca. 17:00 Uhr: Ende\n\nTechnische Anforderungen\n\nLaptop (mit Python/Jupyter oder alternativ Google Colab)\n\nSpeaker\n\nChristian Winkler beschäftigt sich seit vielen Jahre mit künstlicher Intelligenz, speziell in der automatisierten Analyse natürlichsprachiger Texte (NLP). Als Professor an der TH Nürnberg konzentriert sich seine Forschung auf die Optimierung von User Experience mithilfe moderner Verfahren. Er forscht und publiziert zu AI/NLP und ist regelmäßig Sprecher auf Konferenzen. Jetzt Tickets sichern']","Die Sentimentanalyse wird im Workshop mit LLMs durchgeführt, um die Stimmungen zu bestimmen. Daraus ergeben sich Zeitserien, die analysiert werden, um die zukünftige Entwicklung mit unterschiedlichen Methoden vorherzusagen.",simple,"[{'source': '../data/Datenanalyse_mit_Machine_Learning.md', 'filename': '../data/Datenanalyse_mit_Machine_Learning.md'}]",True
5,Welche 4 Risikogruppen für KI-Systeme erfordern MLOps und Data-Governance?,"['Die Engineering-Perspektive auf den EU AI Act\n\nTrustworthy AI ist eine zentrale Motivation hinter dem EU AI Act. Dieser gesetzliche Rahmen legt vielschichtige und anspruchsvolle Anforderungen an KI- Systeme fest und kategorisiert sie in vier Risikogruppen: verbotene, hochriskante, begrenzt riskante KI-Systeme und solche mit minimalem Risiko.\n\nAngesichts der Schonfrist von 6 bis 24 Monaten nach Veröffentlichung der Verordnung wird empfohlen, dass Unternehmen, die KI einsetzen, mit der Vorbereitung auf die zukünftigen Anforderungen beginnen. Um die technische Bereitschaft für die Einhaltung des AI Act zu erreichen, ist es wesentlich, etablierte Data-Governance, KI-Governance und MLOps-Techniken über die gesamte Lebensdauer eines ML/AI-Systems anzuwenden.\n\nDieser Vortrag zielt darauf ab, Entwickler und Data Science Teams mit einem umfassenden Verständnis der Anforderungen des EU AI Act auszustatten. Er bietet auch praktische Anleitungen zur Implementierung von MLOps und Data- Governance-Prozessen, die der Verordnung entsprechen. Dieser Vortrag wird die Ingenieursperspektive auf die proaktive Implementierung des EU AI Act geben.\n\nVorkenntnisse\n\nErfahrung mit MLOps\n\nLernziele\n\nNach dem Talk sind ML Engineers in der Lage, proaktiv konforme MLOps-Prozesse und -Systeme zu entwerfen und zu implementieren und dabei die regulatorischen Anforderungen effektiv zu meistern.\n\nSpeaker\n\nLarysa Visengeriyeva ist Technologieberaterin und Expertin für Datenqualität, maschinelles Lernen und MLOps. Sie promovierte in Augmented Data Quality Management an der TU Berlin. Bei INNOQ.AI ist sie Head of Data and AI und arbeitet an der Operationalisierung von ML-Systemen und Datenarchitekturen. Larysa gründete das Sommerfestival Women+ in Data and AI. __@visenger Jetzt Tickets sichern']","Die vier Risikogruppen für KI-Systeme sind verbotene, hochriskante, begrenzt riskante KI-Systeme und solche mit minimalem Risiko.",reasoning,"[{'source': '../data/Die_Engineering-Perspektive_auf_den_EU_AI_Act.md', 'filename': '../data/Die_Engineering-Perspektive_auf_den_EU_AI_Act.md'}]",True
6,Wie verbessert Christian Winkler die UX in NLP mit modernen Verfahren?,"['Eine Einführung in Large Language Models\n\nChatGPT ist fast schon zum Synonym für große Sprachmodelle geworden. Doch das ist nur die Spitze des Eisbergs – es gibt diese Modelle in viel mehr unterschiedlichen Ausprägungen.\n\nNach der Einführung der Transformer-Architektur durch Google gab es eine wahre Explosion an neuen Modellen. Grundsätzlich kann man zwischen Encoder- und (generativen) Decoder-Modellen unterscheiden, die sich für unterschiedliche Aufgaben eignen.\n\nDieser Vortrag gibt einen Überblick über die Architektur und die Entwicklung der unterschiedlichen Modelle. Er zeigt, dass sich Modelle auch leicht auf eigener Hardware oder mit kostenlosen Cloud-Diensten ausprobieren lassen und wie man das mit etwas Mühe auch ohne GPU auf der eigenen Hardware ausprobieren kann.\n\nDer Ausblick wagt eine Vorhersage, wie es mit den großen Sprachmodellen vielleicht weitergehen könnte.\n\nVorkenntnisse\n\nMit Sprachmodellen als Anwender hat vermutlich jeder/r schon gearbeitet. Grundkenntnisse in Machine Learning sind ebenso hilfreich wie ein Grundverständnis von CPUs, GPUs und Arbeitsspeicher.\n\nLernziele\n\nVerständnis der Architektur von großen Sprachmodellen\n\nUnterscheidung von Encoder- und Decoder-Modellen\n\nOptimierungsmöglichkeiten für Sprachmodelle\n\nKenntnis unterschiedlicher generativer Modelle\n\n""Gefühl"" für die weitere Entwicklung\n\nSpeaker\n\nChristian Winkler beschäftigt sich seit vielen Jahre mit künstlicher Intelligenz, speziell in der automatisierten Analyse natürlichsprachiger Texte (NLP). Als Professor an der TH Nürnberg konzentriert er sich auf die Optimierung von User Experience mithilfe moderner Verfahren. Er forscht und publiziert zu Natural Language Processing und ist regelmäßig Sprecher auf Machine Learning-Konferenzen. Jetzt Tickets sichern']",Christian Winkler konzentriert sich auf die Optimierung von User Experience mithilfe moderner Verfahren.,reasoning,"[{'source': '../data/Eine_Einführung_in_Large_Language_Models.md', 'filename': '../data/Eine_Einführung_in_Large_Language_Models.md'}]",True
7,How do data availability and explainable AI impact football vs. other sports?,"['Datenanalysen im Fußball – ein Überblick\n\nSeitdem die Moneyball-Philosophie das Baseball-Spiel revolutionierte, erleben wir in unterschiedlichen Sportarten teils gravierende Veränderungen – durch die zunehmende Verfügbarkeit von Daten und von Datenexpert:innen. Fußball ist allerdings immer noch eine gewisse Ausnahme, the beautiful game, mehr Kunst als Mechanik, einfacher zu genießen als zu analysieren.\n\nIn diesem Vortrags werden wir einen Blick werfen auf einige der Möglichkeiten und einige der Hindernisse, auf Daten und Analysen, auf Tools und natürlich ""AI"". Und wir werden Ähnlichkeiten und Unterschiede zwischen Fußballteams und Teams in modernen Unternehmen betrachten, vielleicht können wir ja vom Profisport auch etwas lernen über Zusammenarbeit, Leistung und Kultur.\n\nSpeaker\n\nStefan Kühn beschäftigt sich seit vielen Jahren mit Data Science, Machine Learning und mathematischer Grundlagenforschung. Nach Stationen bei codecentric, Zalando, XING, Tom Tailor und Snap Inc. fokussiert er sich in seiner jetzigen Rolle als VP Data & AI bei der air up GmbH auf Themen wie Data Strategy und Organisationsentwicklung, sowie das wichtigste Thema von allen - Data Quality. Darüber hinaus interessiert er sich vor allem für innovative Methoden im Kontext von Deep Learning und verantwortet das Datenscouting für den FC St. Pauli. Jetzt Tickets sichern', 'Wieviel KI müssen wir unseren Kunden erklären?\n\nWährend Menschen immer weiter von KI unterstützt werden und das Leben scheinbar einfacher wird, nimmt die technische Komplexität unserer Welt ständig zu. Wo vor zehn Jahren noch ein grundsätzliches Verständnis von Web- Technologien ausreichte, um ""das moderne Leben"" zu begreifen, nimmt die Halbwertszeit selbst von Expertenwissen in der KI immer weiter ab.\n\nFür uns gibt es Konferenzen. Doch wieviel KI muss der Fachbereich begreifen, um nicht komplett abgehängt zu werden? Von wie wenig Vorwissen müssen wir ausgehen, wenn wir Data Analytics und KI-Lösungen mit nichttechnischen Personen diskutieren? Egal ob interne Datenabteilung oder externer Dienstleister: Welche Erklärungen müssen folgen, wenn der Fachbereich denkt, dass wir etwas ""einfach mit KI lösen…""?\n\nVorkenntnisse\n\nKeine Vorkenntnisse erforderlich. Lediglich ein Interesse an der Thematik, die über den technischen Aspekt hinausgeht.\n\nLernziele\n\nIch plane Impulse für all diejenigen zu geben, die mit nichttechnischen Personen über KI sprechen wollen und müssen: beim Tischgespräch in der Familie, beim Kundenpitch oder als Verantwortliche für Datenkultur, Change Management oder in der Politik.\n\nAnhand der Merck KGaA zeige ich, wie wir diese Themen den Fachbereichen näherbringen, etwa durch eine interne Datenakademie, in der Interessierte bis hin zum ""Citizen Data Scientist"" ausgebildet werden können.\n\nSpeaker\n\nBoris Adryan ist der Akademische Direktor der internen Data & Digital Academy beim chemisch-pharmazeutischen Unternehmen Merck KGaA. Dort plant und liefert er die Lerninhalte für alle Themen vom grundsätzlichen Datenverständnis bis hin zu generativer KI. Eigene Erfahrung sammelte er in einem Jahrzehnt akademischer Forschung im Bereich angewandter ML sowie als Data Scientist in der Industrie. Jetzt Tickets sichern']","The context discusses the impact of data availability and AI on football, noting that while other sports have seen significant changes due to data and data experts, football remains somewhat of an exception. It is described as more of an art than a mechanical process, easier to enjoy than to analyze. The context does not provide a direct comparison of the impact of explainable AI on football versus other sports.",multi_context,"[{'source': '../data/Datenanalysen_im_Fußball_–_ein_Überblick.md', 'filename': '../data/Datenanalysen_im_Fußball_–_ein_Überblick.md'}, {'source': '../data/Wieviel_KI_müssen_wir_unseren_Kunden_erklären_.md', 'filename': '../data/Wieviel_KI_müssen_wir_unseren_Kunden_erklären_.md'}]",True
8,"How has Kira Engelhardt's finance background and E.ON leadership shaped her AI management, esp. with non-tech stakeholders?","['KI Power-Play: Realistisches Erwartungsmanagement für maximalen Business\n\nImpact Mit dem Hype um GenAI stehen wir als Data Scientists vor der Herausforderung, die hohen (und manchmal unrealistischen) Erwartungen an KI zu managen.\n\nEs braucht die richtigen Herangehensweisen, um mit Daten und KI echten Business Impact zu schaffen, und um somit Enttäuschungen zu vermeiden. Dabei ist es wichtig effiziente Kollaboration zwischen Data Scientists und Business Experten zu ermöglichen. Letztendlich können wir dann sogar GenAI nutzen, um uns bei dieser Herausforderung zu unterstützen.\n\nSpeaker\n\nKira Engelhardt studierte Data Science an der LMU in München und verfügt über mehr als ein Jahrzehnt relevante Erfahrung in der Transformation wichtiger Geschäftsprozesse durch Data Science, Daten und KI. Sie begann ihre Karriere in der Finanzbranche und arbeitete als Data Scientist bei HUK Coburg, KPMG und der Allianz. Nach mehreren Jahren Erfahrung als KI-Projektleiterin in Deutschland und Schweden bei E.ON leitet sie nun das globale Data- und KI- Inhouse-Consulting-Team für Energy Networks bei E.ON. Ihr Ziel ist es, die Digitalisierung unserer Strom- und Gasnetze voranzutreiben und so die Energiewende zu ermöglichen. Jetzt Tickets sichern', 'Wieviel KI müssen wir unseren Kunden erklären?\n\nWährend Menschen immer weiter von KI unterstützt werden und das Leben scheinbar einfacher wird, nimmt die technische Komplexität unserer Welt ständig zu. Wo vor zehn Jahren noch ein grundsätzliches Verständnis von Web- Technologien ausreichte, um ""das moderne Leben"" zu begreifen, nimmt die Halbwertszeit selbst von Expertenwissen in der KI immer weiter ab.\n\nFür uns gibt es Konferenzen. Doch wieviel KI muss der Fachbereich begreifen, um nicht komplett abgehängt zu werden? Von wie wenig Vorwissen müssen wir ausgehen, wenn wir Data Analytics und KI-Lösungen mit nichttechnischen Personen diskutieren? Egal ob interne Datenabteilung oder externer Dienstleister: Welche Erklärungen müssen folgen, wenn der Fachbereich denkt, dass wir etwas ""einfach mit KI lösen…""?\n\nVorkenntnisse\n\nKeine Vorkenntnisse erforderlich. Lediglich ein Interesse an der Thematik, die über den technischen Aspekt hinausgeht.\n\nLernziele\n\nIch plane Impulse für all diejenigen zu geben, die mit nichttechnischen Personen über KI sprechen wollen und müssen: beim Tischgespräch in der Familie, beim Kundenpitch oder als Verantwortliche für Datenkultur, Change Management oder in der Politik.\n\nAnhand der Merck KGaA zeige ich, wie wir diese Themen den Fachbereichen näherbringen, etwa durch eine interne Datenakademie, in der Interessierte bis hin zum ""Citizen Data Scientist"" ausgebildet werden können.\n\nSpeaker\n\nBoris Adryan ist der Akademische Direktor der internen Data & Digital Academy beim chemisch-pharmazeutischen Unternehmen Merck KGaA. Dort plant und liefert er die Lerninhalte für alle Themen vom grundsätzlichen Datenverständnis bis hin zu generativer KI. Eigene Erfahrung sammelte er in einem Jahrzehnt akademischer Forschung im Bereich angewandter ML sowie als Data Scientist in der Industrie. Jetzt Tickets sichern']","Kira Engelhardt's finance background and leadership at E.ON have shaped her AI management by providing her with extensive experience in transforming key business processes through Data Science, data, and AI. Her career progression from the finance sector to leading a global Data and AI Inhouse-Consulting team at E.ON has equipped her with the skills to drive digitalization in energy networks and manage the expectations of non-technical stakeholders effectively.",multi_context,"[{'source': '../data/KI_Power-Play__Realistisches_Erwartungsmanagement_für_maximalen_Business_Impact.md', 'filename': '../data/KI_Power-Play__Realistisches_Erwartungsmanagement_für_maximalen_Business_Impact.md'}, {'source': '../data/Wieviel_KI_müssen_wir_unseren_Kunden_erklären_.md', 'filename': '../data/Wieviel_KI_müssen_wir_unseren_Kunden_erklären_.md'}]",True
9,"Welche technischen Anforderungen gibt es für Teilnehmer, die Python und Jupyter/Colab nutzen möchten?","['Datenanalyse mit Machine Learning\n\nIn diesem Workshop führen wir ein Analyseprojekt durch und nutzen dazu unterschiedliche Methoden.\n\nBasis bilden unstrukturierte Daten aus dem Technology-Subreddit, die wir zunächst statistisch analysieren. Anschließend werden wir die Datenmenge mittels Klassifikation einengen und versuchen, die Inhalte genauer zu verstehen. Dazu kommt Topic Modeling als unüberwachtes Machine Learning im Bereich NLP zum Einsatz.\n\nSchließlich werden wir die Sentiments mit LLMs bestimmen. Daraus ergeben sich Zeitserien, die wir analysieren die zukünftige Entwicklung mit unterschiedlichen Methoden vorhersagen.\n\nVorkenntnisse\n\nPython wäre hilfreich, muss aber nicht unbedingt sein Wer seinen eigenen Computer nutzen will, sollte Jupyter installieren, es geht aber auch mit Colab.\n\nLernziele\n\nKennenlernen unterschiedlicher Datenanalysemethoden\n\nÜberwachtes und unüberwachtes Machine Learning\n\nLLMs und Transformer\n\nZeitserien-Vorhersagen\n\nProjektablauf in komplexen Analyseprojekten kennenlernen\n\nAgenda\n\nPausenzeiten * ab 09:00 Uhr: Registrierung und Begrüßungskaffee * 10:00 Uhr: Beginn * 12:30 - 13:30 Uhr: Mittagspause * 15:00 - 15:15 Uhr: Kaffeepause * 16:15 - 16:30 Uhr: Kaffeepause * ca. 17:00 Uhr: Ende\n\nTechnische Anforderungen\n\nLaptop (mit Python/Jupyter oder alternativ Google Colab)\n\nSpeaker\n\nChristian Winkler beschäftigt sich seit vielen Jahre mit künstlicher Intelligenz, speziell in der automatisierten Analyse natürlichsprachiger Texte (NLP). Als Professor an der TH Nürnberg konzentriert sich seine Forschung auf die Optimierung von User Experience mithilfe moderner Verfahren. Er forscht und publiziert zu AI/NLP und ist regelmäßig Sprecher auf Konferenzen. Jetzt Tickets sichern']","Die technischen Anforderungen für Teilnehmer, die Python und Jupyter/Colab nutzen möchten, sind ein Laptop mit Python/Jupyter oder alternativ Google Colab.",simple,"[{'source': '../data/Datenanalyse_mit_Machine_Learning.md', 'filename': '../data/Datenanalyse_mit_Machine_Learning.md'}]",True
